{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yi-c4WoUxRj"
      },
      "source": [
        "**Importing Dependencies**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "P-WcMEaoK2bg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pathlib\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Doh8BT2JpkOR"
      },
      "source": [
        "**Downloading dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuH43UBTU4Ce",
        "outputId": "e631ef53-9d9c-4616-cbb7-b8ef5f186bd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 4s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#Loading the dataset\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file(\"flower_photos\", origin=dataset_url, untar=True)\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "#Splitting the dataset into train and test images\n",
        "(train_images, train_lables), (evaluating_images, evaluating_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "train_images_reshaped = train_images.reshape(60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS1NQXYapePi"
      },
      "source": [
        "**Functions for the task**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mDD7KK9IhwTO"
      },
      "outputs": [],
      "source": [
        "#Function the inform user about the task\n",
        "def task_information():\n",
        "  print(\"Greetings of the day..!!!\\\n",
        "  This task usualyy focuses around the training of various models and saving all the necessary details of all the models\\\n",
        "  into csv files. The quantity of total number of models depends on user's choice and users are allowed to tune hyperparameter\\\n",
        "  at every layer of the individual model.  \")\n",
        "\n",
        "#Creating the model\n",
        "def build_model(num_layers, model_number, input_shape=(28, 28, 1)):\n",
        "  \n",
        "  #Necessary parameters for building the model\n",
        "  i = 1\n",
        "  filters = []\n",
        "  kernel_sizes = []\n",
        "  activations = []\n",
        "  pooling_sizes = []\n",
        "  paddings = []\n",
        "\n",
        "  epochs = int(input(\"Enter the number of epochs for Model {}: \".format(model_number)))\n",
        "  print(\"\")\n",
        "\n",
        "  #Loop to build the number of layers of the model, #Get idea from my cousin\n",
        "  while i < num_layers+1:\n",
        "    filter_value = int(input(\"Enter filter size for {} layer: \".format(i)))\n",
        "    filters.append(filter_value)\n",
        "\n",
        "    kernel_size_value = int(input(\"Enter kernel size for {} layer: \".format(i)))\n",
        "    kernel_sizes.append(kernel_size_value)\n",
        "\n",
        "    activation_value = input(\"Enter activation function for {} layer: \".format(i))\n",
        "    activations.append(activation_value)\n",
        "\n",
        "    pooling_size_value = int(input(\"Enter pooling size for {} layer: \".format(i)))\n",
        "    pooling_sizes.append(pooling_size_value)\n",
        "\n",
        "    padding_value = input(\"Enter the padding value for {} layer: \".format(i))\n",
        "    paddings.append(padding_value)\n",
        "\n",
        "    print()\n",
        "    i += 1\n",
        "\n",
        "  #Using sequential as base model for the neural network\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n",
        "\n",
        "  #Using zip function to implement crucial parameters in the layers, #Get idea from my cousin\n",
        "  for filter, kernel_size, activation, pool_size, padding, i in zip(filters, kernel_sizes, activations, pooling_sizes, paddings, range(1, num_layers+1)):\n",
        "      model.add(Conv2D(filters=filter, kernel_size=(kernel_size,kernel_size), activation=activation, padding=padding))\n",
        "      model.add(MaxPooling2D(pool_size=(pool_size,pool_size)))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(units=10, activation='softmax'))\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "  history = model.fit(train_images_reshaped, train_lables, epochs = epochs, validation_split = 0.4)\n",
        "  return history, model, epochs\n",
        "\n",
        "#Accumulating all the functions in one main function\n",
        "def main():\n",
        "  #Introduction of the task\n",
        "  task_information()\n",
        "  print(\"\")\n",
        "\n",
        "  number_models = int(input(\"Please enter the number of models: \"))\n",
        "  print(\"\")\n",
        "\n",
        "  dataframe = pd.DataFrame(columns=['Model Name', 'Architecture' ,'Training Accuracy', 'Validation Accuracy', 'Training Loss', 'Validation Loss', 'Epochs'])\n",
        "\n",
        "  i = 1\n",
        "  #Loop used to ask user to put parameters for each layers\n",
        "  while i < number_models+1:\n",
        "    summary = []\n",
        "    print(\"\")\n",
        "    print(\"Enter the details of achitecture and hyperparameters for Model {}\".format(i))\n",
        "    layers = int(input(\"Enter the layers for Model {}: \".format(i)))\n",
        "    print(\"\")\n",
        "    history, model, epochs = build_model(layers, i) #Calling build model to return hyperparameters and history of model\n",
        "    model.summary(print_fn=lambda x: summary.append(x)) #Using lambda function that will take number of arguments and returns only one expression #Get help from my cousin\n",
        "    dataframe.loc[i] = [model.name, summary[2:], max(history.history['accuracy']), max(history.history['val_accuracy']), min(history.history['loss']), min(history.history['val_loss']), epochs]\n",
        "    i += 1\n",
        "\n",
        "  #Saving the dataframe of information of all the models\n",
        "  print(dataframe)\n",
        "  dataframe.to_csv('output.csv', encoding = 'utf-8-sig', index=False) \n",
        "  files.download('output.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        },
        "id": "8Rg9G08uYust",
        "outputId": "ae982c50-35ee-4152-d1a5-80f5178c466f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Greetings of the day..!!!  This task usualyy focuses around the training of various models and saving all the necessary details of all the models  into csv files. The quantity of total number of models depends on user's choice and users are allowed to tune hyperparameter  at every layer of the individual model.  \n",
            "\n",
            "Please enter the number of models: 2\n",
            "\n",
            "\n",
            "Enter the details of achitecture and hyperparameters for Model 1\n",
            "Enter the layers for Model 1: 2\n",
            "\n",
            "Enter the number of epochs for Model 1: 1\n",
            "\n",
            "Enter filter size for 1 layer: 2\n",
            "Enter kernel size for 1 layer: 3\n",
            "Enter activation function for 1 layer: relu\n",
            "Enter pooling size for 1 layer: 2\n",
            "Enter the padding value for 1 layer: same\n",
            "\n",
            "Enter filter size for 2 layer: 2\n",
            "Enter kernel size for 2 layer: 2\n",
            "Enter activation function for 2 layer: relu\n",
            "Enter pooling size for 2 layer: 2\n",
            "Enter the padding value for 2 layer: same\n",
            "\n",
            "1125/1125 [==============================] - 67s 59ms/step - loss: 1.6967 - accuracy: 0.4604 - val_loss: 0.8348 - val_accuracy: 0.7198\n",
            "\n",
            "Enter the details of achitecture and hyperparameters for Model 2\n",
            "Enter the layers for Model 2: 1\n",
            "\n",
            "Enter the number of epochs for Model 2: 1\n",
            "\n",
            "Enter filter size for 1 layer: 2\n",
            "Enter kernel size for 1 layer: 2\n",
            "Enter activation function for 1 layer: relu\n",
            "Enter pooling size for 1 layer: 2\n",
            "Enter the padding value for 1 layer: same\n",
            "\n",
            "1125/1125 [==============================] - 46s 40ms/step - loss: 1.5808 - accuracy: 0.6200 - val_loss: 0.5748 - val_accuracy: 0.7988\n",
            "     Model Name                                       Architecture  \\\n",
            "1    sequential  [ Layer (type)                Output Shape    ...   \n",
            "2  sequential_1  [ Layer (type)                Output Shape    ...   \n",
            "\n",
            "   Training Accuracy  Validation Accuracy  Training Loss  Validation Loss  \\\n",
            "1           0.460417             0.719833       1.696749         0.834778   \n",
            "2           0.620028             0.798792       1.580841         0.574816   \n",
            "\n",
            "  Epochs  \n",
            "1      1  \n",
            "2      1  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f1238fe4-0fdc-4037-b6e5-2831d8e23bea\", \"output.csv\", 2858)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}