{"cells":[{"cell_type":"markdown","metadata":{"id":"5yi-c4WoUxRj"},"source":["**Importing Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P-WcMEaoK2bg"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import pathlib\n","import tensorflow as tf\n","import keras\n","import numpy as np\n","import pandas as pd\n","from google.colab import files\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense"]},{"cell_type":"markdown","metadata":{"id":"Doh8BT2JpkOR"},"source":["**Downloading dataset**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FuH43UBTU4Ce"},"outputs":[],"source":["dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n","data_dir = tf.keras.utils.get_file(\"flower_photos\", origin=dataset_url, untar=True)\n","data_dir = pathlib.Path(data_dir)\n","fashion_mnist = keras.datasets.fashion_mnist\n","\n","(train_images, train_lables), (evaluating_images, evaluating_labels) = tf.keras.datasets.fashion_mnist.load_data()\n","train_images_reshaped = train_images.reshape(60000, 28, 28, 1)"]},{"cell_type":"markdown","metadata":{"id":"pS1NQXYapePi"},"source":["**Functions for the task**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDD7KK9IhwTO"},"outputs":[],"source":["def task_information():\n","  print(\"Greetings of the day..!!!\\\n","  This task usualyy focuses around the training of various models and saving all the necessary details of all the models\\\n","  into csv files. The quantity of total number of models depends on user's choice and users are allowed to tune hyperparameter\\\n","  at every layer of the individual model.  \")\n","\n","def build_model(num_layers, model_number, input_shape=(28, 28, 1)):\n","  \n","  i = 1\n","  filters = []\n","  kernel_sizes = []\n","  activations = []\n","  pooling_sizes = []\n","  paddings = []\n","\n","  epochs = int(input(\"Enter the number of epochs for Model {}: \".format(model_number)))\n","  print(\"\")\n","\n","  while i < num_layers+1:\n","    filter_value = int(input(\"Enter filter size for {} layer: \".format(i)))\n","    filters.append(filter_value)\n","\n","    kernel_size_value = int(input(\"Enter kernel size for {} layer: \".format(i)))\n","    kernel_sizes.append(kernel_size_value)\n","\n","    activation_value = input(\"Enter activation function for {} layer: \".format(i))\n","    activations.append(activation_value)\n","\n","    pooling_size_value = int(input(\"Enter pooling size for {} layer: \".format(i)))\n","    pooling_sizes.append(pooling_size_value)\n","\n","    padding_value = input(\"Enter the padding value for {} layer: \".format(i))\n","    paddings.append(padding_value)\n","\n","    print()\n","    i += 1\n","\n","  model = Sequential()\n","  model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=input_shape))\n","\n","  for filter, kernel_size, activation, pool_size, padding, i in zip(filters, kernel_sizes, activations, pooling_sizes, paddings, range(1, num_layers+1)):\n","      model.add(Conv2D(filters=filter, kernel_size=(kernel_size,kernel_size), activation=activation, padding=padding))\n","      model.add(MaxPooling2D(pool_size=(pool_size,pool_size)))\n","\n","  model.add(Flatten())\n","  model.add(Dense(units=10, activation='softmax'))\n","  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","  history = model.fit(train_images_reshaped, train_lables, epochs = epochs, validation_split = 0.4)\n","  return history, model, epochs\n","\n","def main():\n","  task_information()\n","  print(\"\")\n","\n","  number_models = int(input(\"Please enter the number of models: \"))\n","  print(\"\")\n","\n","  dataframe = pd.DataFrame(columns=['Model Name', 'Architecture' ,'Training Accuracy', 'Validation Accuracy', 'Training Loss', 'Validation Loss', 'Epochs'])\n","\n","  i = 1\n","  while i < number_models+1:\n","    summary = []\n","    print(\"\")\n","    print(\"Enter the details of achitecture and hyperparameters for Model {}\".format(i))\n","    layers = int(input(\"Enter the layers for Model {}: \".format(i)))\n","    print(\"\")\n","    history, model, epochs = build_model(layers, i)\n","    model.summary(print_fn=lambda x: summary.append(x))\n","    dataframe.loc[i] = [model.name, summary[2:], max(history.history['accuracy']), max(history.history['val_accuracy']), min(history.history['loss']), min(history.history['val_loss']), epochs]\n","    i += 1\n","\n","  print(dataframe)\n","  dataframe.to_csv('output.csv', encoding = 'utf-8-sig', index=False) \n","  files.download('output.csv')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"8Rg9G08uYust"},"outputs":[],"source":["if __name__ == \"__main__\":\n","  main()"]}],"metadata":{"colab":{"provenance":[{"file_id":"1_rab45JBo8HrDQ-B3sVpyQKe6G43sfTs","timestamp":1676200974565}]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}